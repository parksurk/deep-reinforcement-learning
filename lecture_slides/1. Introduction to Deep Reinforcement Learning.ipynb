{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lesson 1-1: Introduction to RL\n",
    "In this lesson, you'll explore a friendly introduction to reinforcement learning.\n",
    "\n",
    "### Lesson 1-2: The RL Framework: The Problem\n",
    "In this lesson, you'll learn how to specify a real-world problem as a Markov Decision Process (MDP), so that it can be solved with reinforcement learning.\n",
    "\n",
    "### Lesson 1-3: The RL Framework: The Solution\n",
    "In this lesson, you'll learn all about value functions and optimal policies.\n",
    "\n",
    "### Lesson 1-4: Dynamic Programming (Optional)\n",
    "In this lesson, you'll build some intuition for the reinforcement learning problem by learning about a class of solution methods that solve a slightly easier problem. (This lesson is optional and can be accessed in the extracurricular content.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lesson 1-5: Monte Carlo Methods\n",
    "In this lesson, you'll learn about a class of solution methods known as Monte Carlo methods. You'll implement your own Blackjack-playing agent in OpenAI Gym\n",
    "\n",
    "### Lesson 1-6: Temporal-Difference Methods\n",
    "In this lesson, you'll learn how to apply temporal-difference methods such as SARSA, Q-learning, and Expected SARSA to solve both episodic and continuing tasks.\n",
    "\n",
    "### Lesson 1-7: Solve OpenAI Gym's Taxi-v2 Task\n",
    "In this lesson, you'll apply what you've learned to train a taxi to pick up and drop off passengers.\n",
    "\n",
    "### Lesson 1-8: RL in Continuous Spaces\n",
    "In this lesson, you'll explore how to use techniques such as tile coding and coarse coding to expand the size of the problems that can be solved with traditional reinforcement learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reference \n",
    "\n",
    "### Notation - cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"../cheatsheet/cheatsheet.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10ea05860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(\"../cheatsheet/cheatsheet.pdf\", width=800, height=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto - Second Edition] \n",
    "http://incompleteideas.net/book/the-book.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 1-1: Introduction to RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1-1 RL Framework : The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Framework Basic Concepts\n",
    "\n",
    "* agent\n",
    "* envirionment\n",
    "* state\n",
    "* action\n",
    "* reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
